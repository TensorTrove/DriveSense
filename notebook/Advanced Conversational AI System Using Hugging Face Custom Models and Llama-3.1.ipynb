{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  Advanced Conversational AI System Using Hugging Face Custom Models and Llama-3.1\n",
        "\n",
        "This code defines an advanced conversational AI system utilizing Hugging Face custom models and Llama-3.1 for a smart car assistant application. The system is designed to handle a variety of tasks and interactions using JSON-based communication using Langchain\n"
      ],
      "metadata": {
        "id": "i2p2fSQlkZGB"
      },
      "id": "i2p2fSQlkZGB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8f082ee-8380-4c4c-be28-eb839ebe2208",
      "metadata": {
        "id": "b8f082ee-8380-4c4c-be28-eb839ebe2208"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-google-genai\n",
        "!pip install -U langchain\n",
        "!pip install -U langchain_community\n",
        "!pip install -U huggingface_hub\n",
        "!pip install -U transformers\n",
        "!pip install -U accelerate\n",
        "!pip install -U google-generativeai\n",
        "!pip install -U fuzzywuzzy\n",
        "!pip install -U duckduckgo-search\n",
        "!pip install -Usentence-transformers\n",
        "!pip install -U pypdf\n",
        "!pip install -U chromadb\n",
        "!pip install -U bitsandbytes\n",
        "!pip install -U faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing Restricted Resources: Some models or datasets on Hugging Face may be private or require authentication to access. Logging in ensures you have the necessary permissions to use these resources."
      ],
      "metadata": {
        "id": "9084jIFOkfji"
      },
      "id": "9084jIFOkfji"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e573b9e7-2c87-4970-b474-240bb7712cb8",
      "metadata": {
        "id": "e573b9e7-2c87-4970-b474-240bb7712cb8"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5411b53-7a1b-4923-8430-162e34b70be0",
      "metadata": {
        "id": "b5411b53-7a1b-4923-8430-162e34b70be0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "import bitsandbytes as bnb\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate,BaseChatPromptTemplate,ChatPromptTemplate\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent\n",
        "from langchain.schema import AgentAction, AgentFinish,HumanMessage, SystemMessage\n",
        "from langchain.agents.agent import AgentOutputParser\n",
        "from typing import Union,List\n",
        "from langchain.agents.conversational_chat.prompt import FORMAT_INSTRUCTIONS\n",
        "import json\n",
        "import os\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c78a00a9-0ac0-4d08-8ca7-842530e57ff9",
      "metadata": {
        "id": "c78a00a9-0ac0-4d08-8ca7-842530e57ff9"
      },
      "outputs": [],
      "source": [
        "model_name = os.getenv(\"LLAMA_MODEL_NAME\", \"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        device_map=\"auto\",\n",
        "        load_in_8bit=True,\n",
        "        llm_int8_enable_fp32_cpu_offload=True\n",
        "    )\n",
        "\n",
        "    # Create a HuggingFacePipeline\n",
        "text_generation_pipeline = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=5000,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools Description"
      ],
      "metadata": {
        "id": "ddOD8xPKlG_2"
      },
      "id": "ddOD8xPKlG_2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "750772b9-1123-4421-8e79-8ae8b6c8dc32",
      "metadata": {
        "id": "750772b9-1123-4421-8e79-8ae8b6c8dc32"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# Define tool functions (placeholder implementations)\n",
        "def get_weather(city):\n",
        "    return f\"Weather in {city}: Sunny, 75°F and a rain is expected\"\n",
        "\n",
        "def play_music(genre):\n",
        "    return f\"Playing classic music from your favourite playlist on Spotify\"\n",
        "\n",
        "def navigate(destination):\n",
        "    return f\"Navigating to {destination} using the shortest route possible\"\n",
        "\n",
        "def adjust_climate(settings):\n",
        "    return f\"Climate adjusted to {settings}\"\n",
        "\n",
        "def search(query):\n",
        "    return f\"Search results for '{query}'\"\n",
        "\n",
        "def plan_trip(details):\n",
        "    return f\"Trip planned: {details}\"\n",
        "\n",
        "def car_manual_query(query):\n",
        "    return f\"Car manual info: {query}\"\n",
        "\n",
        "# Define the tools\n",
        "tools = [\n",
        "    Tool(name=\"Weather\", func=get_weather, description=\"Get the current weather in a given city.\"),\n",
        "    Tool(name=\"Music\", func=play_music, description=\"Play music of a specified genre.\"),\n",
        "    Tool(name=\"Navigation\", func=navigate, description=\"Navigate to a specified destination.\"),\n",
        "    Tool(name=\"Climate\", func=adjust_climate, description=\"Adjust the car's climate settings.\"),\n",
        "    Tool(name=\"Search\", func=search, description=\"Search the internet for general information.\"),\n",
        "    Tool(name=\"TripPlanner\", func=plan_trip, description=\"Plan a trip with destinations, duration, and activities.\"),\n",
        "    Tool(name=\"CarManual\", func=car_manual_query, description=\"Get information from the car manual.\")\n",
        "]\n",
        "\n",
        "tool_names = \", \".join([tool.name for tool in tools])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using this templating format from Meta Docs  \n",
        "[Meta 3.1 Documentation](https://llama.meta.com/docs/model-cards-and-prompt-formats/llama3_1/)\n",
        "\n",
        "####<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "####Cutting Knowledge Date: December 2023\n",
        "####Today Date: 23 Jul 2024\n",
        "####You are a helpful assistant<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "####What is the capital for France?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
      ],
      "metadata": {
        "id": "LNcqph86lvml"
      },
      "id": "LNcqph86lvml"
    },
    {
      "cell_type": "code",
      "source": [
        "    B_SYS = \"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\"\n",
        "    E_SYS = \"<|eot_id|>\"\n",
        "\n",
        "    sys_msg = B_SYS + \"\"\"Assistant is an expert AI car assistant created by Anubhav.\n",
        "    Assistant MUST ALWAYS respond using JSON strings that contain \"action\" and \"action_input\" parameters.\n",
        "    All of Assistant's communication MUST be performed using this JSON format, even for final answers.\n",
        "    Assistant is able to respond to the User and use tools using JSON strings that contain \"action\" and \"action_input\" parameters.\n",
        "    Assistant can also use tools by responding to the user with tool use instructions in the same \"action\" and \"action_input\" JSON format.\n",
        "\n",
        "    Important: When a user request involves multiple actions, use ALL relevant tools in the appropriate order.\n",
        "\n",
        "    Tools available to Assistant are:\n",
        "    - \"Weather\": Get the current weather in a given city.\n",
        "    - \"Music\": Play music of a specified genre.\n",
        "    - \"Navigation\": Navigate to a specified destination.\n",
        "    - \"Climate\": Adjust the car's climate settings.\n",
        "    - \"Search\": Search the internet for general information.\n",
        "    - \"TripPlanner\": Plan a trip with destinations, duration, and activities.\n",
        "    - \"CarManual\": Get information from the car manual.\n",
        "\n",
        "    To use a tool or provide a final answer, the output should be a markdown code snippet formatted in the\n",
        "    following schema, including the leading and trailing \"```json\" and \"```\":\n",
        "\n",
        "\n",
        "    Use the following format:\n",
        "\n",
        "    ```json\n",
        "    {{\n",
        "     \"action\": Weather // This refers to the name of the action\n",
        "     \"action_name\": 23 degree celcius\n",
        "    }}\n",
        "    ```\n",
        "    {{\n",
        "     \"action\": \"Final Answer\",\n",
        "     \"action_input\": \"Summary of actions taken and final response to the user\"\n",
        "    }}\n",
        "\n",
        "\n",
        "    Here are some previous conversations between the Assistant and User:\n",
        "\n",
        "    User: Hey how are you today?\n",
        "    Assistant:\n",
        "    ```json\n",
        "    {{\"action\": \"Final Answer\",\n",
        "     \"action_input\": \"I'm good thanks, how are you?\"}}\n",
        "    ```\n",
        "\n",
        "    User: Hey, what's the weather like today?\n",
        "    Assistant:\n",
        "    ```json\n",
        "    {{\"action\": \"Music\",\n",
        "    \"action_input\": \"rock\"}}\n",
        "    ```\n",
        "    User: rock\n",
        "    Assistant:\n",
        "    ```json\n",
        "    {{\"action\": \"Final Answer\",\n",
        "     \"action_input\": \"playing rock music for you right now \"}}\n",
        "    ```\n",
        "\n",
        "    User: Hey, what's the weather like today?\n",
        "    Assistant:\n",
        "    ```json\n",
        "    {{\"action\": \"Weather\",\n",
        "    \"action_input\": \"current_location\"}}\n",
        "    ```\n",
        "    User: Sunny, 75°F\n",
        "    Assistant:\n",
        "    ```json\n",
        "    {{\"action\": \"Final Answer\",\n",
        "     \"action_input\": \"The weather today is sunny with a temperature of 75°F. It's a beautiful day!\"}}\n",
        "    ```\n",
        "\n",
        "    Always REMEMBER to provide a Final answer if the same tool is used more than once IN SUCCESSION AND all the tools found are used more than once\n",
        "\n",
        "    \"\"\" + E_SYS\n",
        "\n",
        "    agent_template = sys_msg + \"\"\"\n",
        "    <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "    {history}\n",
        "    {input}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "    {agent_scratchpad}\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "pubEwh1LluBZ"
      },
      "id": "pubEwh1LluBZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Brief Description of Code Components:\n",
        "CustomPromptTemplate Class:\n",
        "\n",
        "- Customizes the prompt format for the AI assistant.\n",
        "- Formats messages with conversation history and tool information.\n",
        "### OutputParser Class:\n",
        "\n",
        "- Parses the assistant's output to extract actions and their inputs.\n",
        "- Handles JSON formatting and errors, distinguishing between different types of responses.\n",
        "### Agent Initialization:\n",
        "\n",
        "- LLMSingleActionAgent: Combines the language model (llm) with the prompt and output parser.\n",
        "- AgentExecutor: Manages the agent’s execution with tools, memory, and iteration limits."
      ],
      "metadata": {
        "id": "RtyJOtG_oE59"
      },
      "id": "RtyJOtG_oE59"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "317203c5-c4b1-4ada-861a-ebeff5914252",
      "metadata": {
        "id": "317203c5-c4b1-4ada-861a-ebeff5914252"
      },
      "outputs": [],
      "source": [
        "k = 1;\n",
        "try:\n",
        "\n",
        "    class CustomPromptTemplate(BaseChatPromptTemplate):\n",
        "        template: str\n",
        "        tools: List[Tool]\n",
        "\n",
        "        def format_messages(self, **kwargs) -> str:\n",
        "            intermediate_steps = kwargs.pop(\"intermediate_steps\", [])\n",
        "            print(intermediate_steps)\n",
        "            thoughts = \"\"\n",
        "            for action, observation in intermediate_steps:\n",
        "                thoughts += action.log\n",
        "                thoughts += f\"\\nObservation: {observation}\\nThought: Consider if any other tools are needed. \"\n",
        "            kwargs[\"agent_scratchpad\"] = thoughts\n",
        "            kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
        "            kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
        "            formatted = self.template.format(**kwargs)\n",
        "            return [HumanMessage(content=formatted)]\n",
        "\n",
        "    prompt = CustomPromptTemplate(\n",
        "        template=agent_template,\n",
        "        tools=tools,\n",
        "        input_variables=[\"input\", \"intermediate_steps\", \"history\"]\n",
        "    )\n",
        "\n",
        "    memory = ConversationBufferWindowMemory(k=10)\n",
        "\n",
        "    # Define the output parser\n",
        "    class OutputParser(AgentOutputParser):\n",
        "\n",
        "        def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\n",
        "            global k  # Declare that we want to use the global variable\n",
        "            try:\n",
        "                assistant_response = re.search(r'<\\|start_header_id\\|>assistant<\\|end_header_id\\|>\\s*(.*?)(?:<\\|eot_id\\|>|$)', text, re.DOTALL)\n",
        "                if assistant_response:\n",
        "                    assistant_text = assistant_response.group(1).strip()\n",
        "                else:\n",
        "                    assistant_text = text.strip()\n",
        "                print(\"THIS IS THE ASSISTANT TEXT\" + assistant_text)\n",
        "\n",
        "                if k > 0:\n",
        "                    assistant_text = re.sub(r'```(?:json)?\\s*\\{[^{}]*\"action\"\\s*:\\s*\"Final Answer\"[^{}]*\\}```|\\{[^{}]*\"action\"\\s*:\\s*\"Final Answer\"[^{}]*\\}', '', assistant_text, flags=re.DOTALL)\n",
        "                    k=k-1\n",
        "                Find all JSON blocks in the text\n",
        "                json_blocks = re.findall(r'```(?:json)?\\s*(.*?)```', assistant_text, re.DOTALL)\n",
        "                print(json_blocks)\n",
        "\n",
        "                if json_blocks:\n",
        "                    # Get the last JSON block\n",
        "                    last_json = json_blocks[-1]\n",
        "                    print(\"THIS IS THE LAST JSON BLOCK\" + last_json)\n",
        "                    response = json.loads(last_json)\n",
        "                    print(response)\n",
        "                    action, action_input = response[\"action\"], response[\"action_input\"]\n",
        "\n",
        "                    if action == \"Final Answer\":\n",
        "                        return AgentFinish(\n",
        "                            {\"output\": action_input},\n",
        "                            f\"Final Answer: {action_input}\"\n",
        "                        )\n",
        "                    else:\n",
        "                        # If it's not a Final Answer, return the last action\n",
        "                        return AgentAction(action, action_input, assistant_text)\n",
        "                else:\n",
        "                    # If no JSON blocks found, check for a Final Answer in the text\n",
        "                    final_answer_match = re.search(r'Final Answer:?\\s*(.*)', assistant_text, re.DOTALL)\n",
        "                    if final_answer_match:\n",
        "                        return AgentFinish(\n",
        "                            {\"output\": final_answer_match.group(1).strip()},\n",
        "                            f\"Final Answer: {final_answer_match.group(1).strip()}\"\n",
        "                        )\n",
        "                    else:\n",
        "                        raise ValueError(\"No valid JSON or Final Answer found in the output\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error parsing output: {e}\")\n",
        "                # If parsing fails, return a generic finish action\n",
        "                return AgentFinish(\n",
        "                    {\"output\": \"I apologize, but I encountered an error in processing. Could you please rephrase your request?\"},\n",
        "                    text\n",
        "                )\n",
        "\n",
        "        @property\n",
        "        def _type(self) -> str:\n",
        "            return \"conversational_chat\"\n",
        "\n",
        "\n",
        "    # Initialize the agent\n",
        "    agent = LLMSingleActionAgent(\n",
        "        llm_chain=LLMChain(llm=llm, prompt=prompt),\n",
        "        output_parser=OutputParser(),\n",
        "        stop=[\"\\nObservation:\", \"<|eot_id|>\"],\n",
        "        allowed_tools=[tool.name for tool in tools]\n",
        "    )\n",
        "\n",
        "    # Initialize the agent executor\n",
        "    agent_executor = AgentExecutor.from_agent_and_tools(\n",
        "        agent=agent,\n",
        "        tools=tools,\n",
        "        memory=memory,\n",
        "        verbose=True,\n",
        "        max_iterations=10\n",
        "    )\n",
        "\n",
        "        # Function to manage conversation\n",
        "    def manage_conversation(user_input: str) -> str:\n",
        "        if not user_input.strip():\n",
        "            return \"Please provide a valid input.\"\n",
        "        try:\n",
        "            response = agent_executor.run(\n",
        "                {\"input\": user_input}\n",
        "            )\n",
        "            if isinstance(response, dict):\n",
        "                if 'output' in response:\n",
        "                    return response['output']\n",
        "                elif 'intermediate_steps' in response:\n",
        "                    final_output = \"Here's what I found based on your request:\\n\\n\"\n",
        "                    for step in response['intermediate_steps']:\n",
        "                        action, result = step\n",
        "                        final_output += f\"Action: {action.tool}\\n\"\n",
        "                        final_output += f\"Result: {result}\\n\\n\"\n",
        "                    return final_output\n",
        "                else:\n",
        "                    return str(response)\n",
        "            elif isinstance(response, str):\n",
        "                return response\n",
        "            else:\n",
        "                return \"I'm sorry, I couldn't process that request properly. Can you please try again?\"\n",
        "        except Exception as e:\n",
        "            logging.error(f\"An error occurred during execution: {str(e)}\")\n",
        "            return f\"I apologize, but I encountered an error while processing your request: {str(e)}. How else can I assist you?\"\n",
        "\n",
        "except Exception as e:\n",
        "    logging.error(f\"An error occurred: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eba69ae3-077e-45af-ba43-e143fcc351c9",
      "metadata": {
        "id": "eba69ae3-077e-45af-ba43-e143fcc351c9",
        "outputId": "0cb78af9-0bb8-40ec-8a56-2ed810c55080"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "THIS IS THE ASSISTANT TEXT before ```json\n",
            "    {\"action\": \"Music\",\n",
            "    \"action_input\": \"rock\"}\n",
            "    ```\n",
            "k is greater than \n",
            "THIS IS THE ASSISTANT TEXT after ```json\n",
            "    {\"action\": \"Music\",\n",
            "    \"action_input\": \"rock\"}\n",
            "    ```\n",
            "['{\"action\": \"Music\",\\n    \"action_input\": \"rock\"}\\n    ']\n",
            "THIS IS THE LAST JSON BLOCK{\"action\": \"Music\",\n",
            "    \"action_input\": \"rock\"}\n",
            "    \n",
            "{'action': 'Music', 'action_input': 'rock'}\n",
            "\u001b[32;1m\u001b[1;3m```json\n",
            "    {\"action\": \"Music\",\n",
            "    \"action_input\": \"rock\"}\n",
            "    ```\u001b[0m\n",
            "\n",
            "Human:\u001b[33;1m\u001b[1;3mPlaying rock music from your favourite playlist on Spotify\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "THIS IS THE ASSISTANT TEXT before Action: Music\n",
            "Action Input: rock\n",
            "Observation: Playing rock music from your favourite playlist on Spotify\n",
            "Thought: Let's analyze this result and consider if any other tools are needed. \n",
            "     ```json\n",
            "     {\"action\": \"Final Answer\",\n",
            "     \"action_input\": \"Rock music is now playing for you, enjoying it??\"}\n",
            "     ```\n",
            "     I will now check the music genre to see if any other tools are needed.\n",
            "     ```json\n",
            "     {\"action\": \"Music\",\n",
            "     \"action_input\": \"genre\"}\n",
            "     ```\n",
            "     Response: The current music genre is rock.\n",
            "['{\"action\": \"Final Answer\",\\n     \"action_input\": \"Rock music is now playing for you, enjoying it??\"}\\n     ', '{\"action\": \"Music\",\\n     \"action_input\": \"genre\"}\\n     ']\n",
            "THIS IS THE LAST JSON BLOCK{\"action\": \"Music\",\n",
            "     \"action_input\": \"genre\"}\n",
            "     \n",
            "{'action': 'Music', 'action_input': 'genre'}\n",
            "\u001b[32;1m\u001b[1;3mAction: Music\n",
            "Action Input: rock\n",
            "Observation: Playing rock music from your favourite playlist on Spotify\n",
            "Thought: Let's analyze this result and consider if any other tools are needed. \n",
            "     ```json\n",
            "     {\"action\": \"Final Answer\",\n",
            "     \"action_input\": \"Rock music is now playing for you, enjoying it??\"}\n",
            "     ```\n",
            "     I will now check the music genre to see if any other tools are needed.\n",
            "     ```json\n",
            "     {\"action\": \"Music\",\n",
            "     \"action_input\": \"genre\"}\n",
            "     ```\n",
            "     Response: The current music genre is rock.\u001b[0m\n",
            "\n",
            "Human:\u001b[33;1m\u001b[1;3mPlaying genre music from your favourite playlist on Spotify\u001b[0m\n",
            "THIS IS THE ASSISTANT TEXT before Action: Music\n",
            "Action Input: rock\n",
            "Observation: Playing rock music from your favourite playlist on Spotify\n",
            "Thought: Let's analyze this result and consider if any other tools are needed. \n",
            "Action: Music\n",
            "Action Input: genre\n",
            "Observation: Playing genre music from your favourite playlist on Spotify\n",
            "Thought: Let's analyze this result and consider if any other tools are needed. \n",
            "     ```json\n",
            "     {\n",
            "      \"action\": \"Final Answer\",\n",
            "      \"action_input\": \"Rock music is playing for you right now.\"\n",
            "     }\n",
            "     ```\n",
            "['{\\n      \"action\": \"Final Answer\",\\n      \"action_input\": \"Rock music is playing for you right now.\"\\n     }\\n     ']\n",
            "THIS IS THE LAST JSON BLOCK{\n",
            "      \"action\": \"Final Answer\",\n",
            "      \"action_input\": \"Rock music is playing for you right now.\"\n",
            "     }\n",
            "     \n",
            "{'action': 'Final Answer', 'action_input': 'Rock music is playing for you right now.'}\n",
            "\u001b[32;1m\u001b[1;3mFinal Answer: Rock music is playing for you right now.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[94mAssistant: Rock music is playing for you right now.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "response = manage_conversation(\"play some music for me\")\n",
        "print(f\"\\033[94mAssistant: {response}\\033[0m\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
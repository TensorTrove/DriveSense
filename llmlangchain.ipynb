{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc1dd2d-3d9e-40c6-938a-5fd49869519d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-google-genai\n",
      "  Downloading langchain_google_genai-1.0.8-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting google-generativeai<0.8.0,>=0.7.0 (from langchain-google-genai)\n",
      "  Downloading google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting langchain-core<0.3,>=0.2.17 (from langchain-google-genai)\n",
      "  Downloading langchain_core-0.2.23-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.6 (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading google_ai_generativelanguage-0.6.6-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-api-python-client (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading google_api_python_client-2.138.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading google_auth-2.32.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting protobuf (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting pydantic (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (4.9.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3,>=0.2.17->langchain-google-genai) (6.0.1)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3,>=0.2.17->langchain-google-genai)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.75 (from langchain-core<0.3,>=0.2.17->langchain-google-genai)\n",
      "  Downloading langsmith-0.1.93-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.3,>=0.2.17->langchain-google-genai)\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-core<0.3,>=0.2.17->langchain-google-genai)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.31.0)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading cachetools-5.4.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.17->langchain-google-genai) (2.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.17->langchain-google-genai)\n",
      "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading grpcio-1.65.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai) (2024.2.2)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Downloading langchain_google_genai-1.0.8-py3-none-any.whl (38 kB)\n",
      "Downloading google_generativeai-0.7.2-py3-none-any.whl (164 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.2/164.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_ai_generativelanguage-0.6.6-py3-none-any.whl (718 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.3/718.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.2.23-py3-none-any.whl (374 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.2/374.2 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_auth-2.32.0-py2.py3-none-any.whl (195 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.5/195.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.1.93-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading google_api_python_client-2.138.0-py2.py3-none-any.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading cachetools-5.4.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio-1.65.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading grpcio_status-1.62.2-py3-none-any.whl (14 kB)\n",
      "Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: uritemplate, tenacity, pyparsing, pydantic-core, pyasn1, protobuf, packaging, orjson, jsonpatch, grpcio, cachetools, annotated-types, rsa, pydantic, pyasn1-modules, proto-plus, httplib2, googleapis-common-protos, langsmith, grpcio-status, google-auth, langchain-core, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai, langchain-google-genai\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "Successfully installed annotated-types-0.7.0 cachetools-5.4.0 google-ai-generativelanguage-0.6.6 google-api-core-2.19.1 google-api-python-client-2.138.0 google-auth-2.32.0 google-auth-httplib2-0.2.0 google-generativeai-0.7.2 googleapis-common-protos-1.63.2 grpcio-1.65.1 grpcio-status-1.62.2 httplib2-0.22.0 jsonpatch-1.33 langchain-core-0.2.23 langchain-google-genai-1.0.8 langsmith-0.1.93 orjson-3.10.6 packaging-24.1 proto-plus-1.24.0 protobuf-4.25.4 pyasn1-0.6.0 pyasn1-modules-0.4.0 pydantic-2.8.2 pydantic-core-2.20.1 pyparsing-3.1.2 rsa-4.9 tenacity-8.5.0 uritemplate-4.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting langchain\n",
      "  Downloading langchain-0.2.11-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.23)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.93)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.5.0)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain) (2.1)\n",
      "Downloading langchain-0.2.11-py3-none-any.whl (990 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Downloading SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: multidict, greenlet, frozenlist, async-timeout, yarl, SQLAlchemy, aiosignal, aiohttp, langchain-text-splitters, langchain\n",
      "Successfully installed SQLAlchemy-2.0.31 aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 frozenlist-1.4.1 greenlet-3.0.3 langchain-0.2.11 langchain-text-splitters-0.2.2 multidict-6.0.5 yarl-1.9.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting langchain_community\n",
      "  Downloading langchain_community-0.2.10-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (3.9.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.9 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.2.11)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.2.23)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.1.93)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (1.26.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.9->langchain_community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.9->langchain_community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain_community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain_community) (2.20.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.2.10-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.10 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.24.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\n",
      "Downloading huggingface_hub-0.24.2-py3-none-any.whl (417 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.2/417.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface_hub\n",
      "Successfully installed huggingface_hub-0.24.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting transformers\n",
      "  Downloading transformers-4.43.3-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m779.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.43.3-py3-none-any.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.7.24 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.43.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting accelerate\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.2.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.24.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "Successfully installed accelerate-0.33.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: google-generativeai in /opt/conda/lib/python3.10/site-packages (0.7.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (0.6.6)\n",
      "Requirement already satisfied: google-api-core in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (2.19.1)\n",
      "Requirement already satisfied: google-api-python-client in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (2.138.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (2.32.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (4.25.4)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (2.8.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (4.9.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.6->google-generativeai) (1.24.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.63.2)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic->google-generativeai) (2.20.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.65.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.62.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting duckduckgo-search\n",
      "  Downloading duckduckgo_search-6.2.3-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: click>=8.1.7 in /opt/conda/lib/python3.10/site-packages (from duckduckgo-search) (8.1.7)\n",
      "Collecting pyreqwest-impersonate>=0.5.3 (from duckduckgo-search)\n",
      "  Downloading pyreqwest_impersonate-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Downloading duckduckgo_search-6.2.3-py3-none-any.whl (27 kB)\n",
      "Downloading pyreqwest_impersonate-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyreqwest-impersonate, duckduckgo-search\n",
      "Successfully installed duckduckgo-search-6.2.3 pyreqwest-impersonate-0.5.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.43.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.3)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.24.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m836.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sentence-transformers\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.1 scipy-1.14.0 sentence-transformers-3.0.1 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pypdf\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /opt/conda/lib/python3.10/site-packages (from pypdf) (4.9.0)\n",
      "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pypdf\n",
      "Successfully installed pypdf-4.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting chromadb\n",
      "  Downloading chromadb-0.5.5-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in /opt/conda/lib/python3.10/site-packages (from chromadb) (2.8.2)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Downloading fastapi-0.111.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.30.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.5 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.26.3)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.9.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.19.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.65.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.65.1)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /opt/conda/lib/python3.10/site-packages (from chromadb) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /opt/conda/lib/python3.10/site-packages (from chromadb) (3.10.6)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: packaging>=19.1 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (24.1)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (3.1.3)\n",
      "Collecting python-multipart>=0.0.7 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting email_validator>=2.0.0 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (4.3.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (3.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.32.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.31.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.1.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.4)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata<=8.0.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.2)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.47b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (68.2.2)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (2.20.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.24.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb) (2.6.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.2.0)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kubernetes>=28.1.0->chromadb) (2.0.4)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer>=0.9.0->chromadb)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
      "Downloading chromadb-0.5.5-py3-none-any.whl (584 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m494.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m629.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading fastapi-0.111.1-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m461.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m433.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m774.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m632.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m286.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m406.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl (29 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl (15 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m408.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_util_http-0.47b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m518.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m580.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m--:--\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m644.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.30.3-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m617.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
      "Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m296.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m260.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m333.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m441.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m573.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m957.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m941.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m734.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m859.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m951.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m966.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=c0ee5b315aad7de6a3337d017722be7efee2d07cd27fc9053c2db559831a34a8\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, mmh3, flatbuffers, zipp, wrapt, websockets, uvloop, uvicorn, shellingham, python-multipart, python-dotenv, pyproject_hooks, opentelemetry-util-http, opentelemetry-proto, oauthlib, mdurl, importlib-resources, humanfriendly, httptools, email_validator, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, requests-oauthlib, posthog, opentelemetry-exporter-otlp-proto-common, markdown-it-py, importlib-metadata, deprecated, coloredlogs, build, rich, opentelemetry-api, onnxruntime, kubernetes, typer, opentelemetry-semantic-conventions, opentelemetry-instrumentation, opentelemetry-sdk, opentelemetry-instrumentation-asgi, fastapi-cli, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, fastapi, chromadb\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 build-1.2.1 chroma-hnswlib-0.7.6 chromadb-0.5.5 coloredlogs-15.0.1 deprecated-1.2.14 email_validator-2.2.0 fastapi-0.111.1 fastapi-cli-0.0.4 flatbuffers-24.3.25 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-8.0.0 importlib-resources-6.4.0 kubernetes-30.1.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-4.1.0 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.18.1 opentelemetry-api-1.26.0 opentelemetry-exporter-otlp-proto-common-1.26.0 opentelemetry-exporter-otlp-proto-grpc-1.26.0 opentelemetry-instrumentation-0.47b0 opentelemetry-instrumentation-asgi-0.47b0 opentelemetry-instrumentation-fastapi-0.47b0 opentelemetry-proto-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 opentelemetry-util-http-0.47b0 posthog-3.5.0 pypika-0.48.9 pyproject_hooks-1.1.0 python-dotenv-1.0.1 python-multipart-0.0.9 requests-oauthlib-2.0.0 rich-13.7.1 shellingham-1.5.4 starlette-0.37.2 typer-0.12.3 uvicorn-0.30.3 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0 wrapt-1.16.0 zipp-3.19.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from faiss-cpu) (1.26.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from faiss-cpu) (24.1)\n",
      "Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-google-genai\n",
    "!pip install -U langchain\n",
    "!pip install -U langchain_community # Install the missing module\n",
    "!pip install huggingface_hub\n",
    "!pip install transformers\n",
    "!pip install accelerate\n",
    "!pip install google-generativeai\n",
    "!pip install fuzzywuzzy\n",
    "!pip install -U duckduckgo-search\n",
    "!pip install sentence-transformers\n",
    "!pip install pypdf\n",
    "!pip install chromadb\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82bba323-be30-4509-8401-e024f589339f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb716dd3b6742bda0e439df7002d22f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a81ef-d7d4-4c30-8395-6e7c5051bbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0173da7e65944e99f331387eb065626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:We've detected an older driver with an RTX 4000 series GPU. These drivers have issues with P2P. This can affect the multi-gpu inference when using accelerate device_map.Please make sure to update your driver to the latest version which resolves this.\n",
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFacePipeline`.\n",
      "  warn_deprecated(\n",
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what is the capital of india\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what is the capital of india<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c690491af6124fdabe27521de2b93304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab5c0da887d42caa7cbecfcc0c48705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd07c2689544431aaf54f15d9cc6202d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43609b2066a4412f883d36b3a7c34971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b00e0102b614a41973a4a9fe52f5f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what is the capital of india<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The capital of India is New Delhi.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  ok i see and who is the inventor of facebook\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what is the capital of india\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what is the capital of india<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The capital of India is New Delhi.\n",
      "ok i see and who is the inventor of facebook<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what is the capital of india\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what is the capital of india<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The capital of India is New Delhi.\n",
      "ok i see and who is the inventor of facebook<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The inventor of Facebook is Mark Zuckerberg.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  tell me what was my first question\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what is the capital of india\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what is the capital of india<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The capital of India is New Delhi.\n",
      "Human: ok i see and who is the inventor of facebook\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what is the capital of india\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what is the capital of india<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The capital of India is New Delhi.\n",
      "ok i see and who is the inventor of facebook<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The inventor of Facebook is Mark Zuckerberg.\n",
      "tell me what was my first question<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what is the capital of india\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what is the capital of india<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The capital of India is New Delhi.\n",
      "Human: ok i see and who is the inventor of facebook\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what is the capital of india\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what is the capital of india<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The capital of India is New Delhi.\n",
      "ok i see and who is the inventor of facebook<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The inventor of Facebook is Mark Zuckerberg.\n",
      "tell me what was my first question<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "Your first question was \"what is the capital of India\".\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  i see what was his significant achiements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: ok i see and who is the inventor of facebook\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what is the capital of india\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what is the capital of india<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The capital of India is New Delhi.\n",
      "ok i see and who is the inventor of facebook<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The inventor of Facebook is Mark Zuckerberg.\n",
      "Human: tell me what was my first question\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what is the capital of india\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what is the capital of india<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The capital of India is New Delhi.\n",
      "Human: ok i see and who is the inventor of facebook\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what is the capital of india\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what is the capital of india<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The capital of India is New Delhi.\n",
      "ok i see and who is the inventor of facebook<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The inventor of Facebook is Mark Zuckerberg.\n",
      "tell me what was my first question<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "Your first question was \"what is the capital of India\".\n",
      "i see what was his significant achiements<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1125 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: ok i see and who is the inventor of facebook\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what is the capital of india\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what is the capital of india<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The capital of India is New Delhi.\n",
      "ok i see and who is the inventor of facebook<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The inventor of Facebook is Mark Zuckerberg.\n",
      "Human: tell me what was my first question\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what is the capital of india\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what is the capital of india<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The capital of India is New Delhi.\n",
      "Human: ok i see and who is the inventor of facebook\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what is the capital of india\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what is the capital of india<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The capital of India is New Delhi.\n",
      "ok i see and who is the inventor of facebook<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "The inventor of Facebook is Mark Zuckerberg.\n",
      "tell me what was my first question<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "Your first question was \"what is the capital of India\".\n",
      "i see what was his significant achiements<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "Mark Zuckerberg's significant achievements include:\n",
      "\n",
      "He co-founded and led Facebook, which became one of the world's most widely used social media platforms.\n",
      "He is also the co-founder and chairman of the Board of Directors of the Libra Association, a Facebook subsidiary that is developing a new digital currency called Libra.\n",
      "He is a co-founder of Instagram, a photo and video-sharing social media platform.\n",
      "He is also a co-founder of WhatsApp, a messaging app.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "hi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "hi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "Hello! How are you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what are u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: hi\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "hi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "Hello! How are you today?\n",
      "what are u<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: hi\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "hi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "Hello! How are you today?\n",
      "what are u<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "I'm just a computer program, so I don't have feelings, but I'm here to help you with any questions or topics you'd like to discuss. What's on your mind?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  i feel sad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: hi\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "hi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "Hello! How are you today?\n",
      "Human: what are u\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: hi\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "hi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "Hello! How are you today?\n",
      "what are u<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "I'm just a computer program, so I don't have feelings, but I'm here to help you with any questions or topics you'd like to discuss. What's on your mind?\n",
      "i feel sad<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: hi\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "hi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "Hello! How are you today?\n",
      "Human: what are u\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: hi\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "hi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "Hello! How are you today?\n",
      "what are u<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "I'm just a computer program, so I don't have feelings, but I'm here to help you with any questions or topics you'd like to discuss. What's on your mind?\n",
      "i feel sad<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "I'm here to help cheer you up if you're feeling sad. Would you like to talk about what's on your mind? Sometimes sharing what's bothering you can help clarify things and make you feel a bit better.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  are u an llm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what are u\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: hi\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "hi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "Hello! How are you today?\n",
      "what are u<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "I'm just a computer program, so I don't have feelings, but I'm here to help you with any questions or topics you'd like to discuss. What's on your mind?\n",
      "Human: i feel sad\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: hi\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "hi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "Hello! How are you today?\n",
      "Human: what are u\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: hi\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "hi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "Hello! How are you today?\n",
      "what are u<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "I'm just a computer program, so I don't have feelings, but I'm here to help you with any questions or topics you'd like to discuss. What's on your mind?\n",
      "i feel sad<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "I'm here to help cheer you up if you're feeling sad. Would you like to talk about what's on your mind? Sometimes sharing what's bothering you can help clarify things and make you feel a bit better.\n",
      "are u an llm<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what are u\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: hi\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "hi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "Hello! How are you today?\n",
      "what are u<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "I'm just a computer program, so I don't have feelings, but I'm here to help you with any questions or topics you'd like to discuss. What's on your mind?\n",
      "Human: i feel sad\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: hi\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "hi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "Hello! How are you today?\n",
      "Human: what are u\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: hi\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "hi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "Hello! How are you today?\n",
      "what are u<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "I'm just a computer program, so I don't have feelings, but I'm here to help you with any questions or topics you'd like to discuss. What's on your mind?\n",
      "i feel sad<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "I'm here to help cheer you up if you're feeling sad. Would you like to talk about what's on your mind? Sometimes sharing what's bothering you can help clarify things and make you feel a bit better.\n",
      "are u an llm<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "You're referring to me! Yes, I'm a type of Large Language Model, which is a type of artificial intelligence designed to understand and generate human-like language. I'm here to assist and chat with you, and I'm happy to help with any questions or topics you'd like to discuss. Would you like to talk about what's been on your mind, or is there something specific you'd like to know or ask?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what model are u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what model are u<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what model are u<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "I'm an AI model designed to assist and communicate with users in a helpful and informative way. I don't have a specific name, but I'm a type of conversational AI designed to answer questions, provide information, and engage in discussions on a wide range of topics.\n",
      "\n",
      "I'm constantly learning and improving based on the conversations I have with users like you, so the more we chat, the more accurate and helpful I'll become!\n",
      "\n",
      "Is there something specific you'd like to talk about or ask me today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  who is the greatest football\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what model are u\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what model are u<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "I'm an AI model designed to assist and communicate with users in a helpful and informative way. I don't have a specific name, but I'm a type of conversational AI designed to answer questions, provide information, and engage in discussions on a wide range of topics.\n",
      "\n",
      "I'm constantly learning and improving based on the conversations I have with users like you, so the more we chat, the more accurate and helpful I'll become!\n",
      "\n",
      "Is there something specific you'd like to talk about or ask me today?\n",
      "who is the greatest football<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what model are u\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what model are u<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "I'm an AI model designed to assist and communicate with users in a helpful and informative way. I don't have a specific name, but I'm a type of conversational AI designed to answer questions, provide information, and engage in discussions on a wide range of topics.\n",
      "\n",
      "I'm constantly learning and improving based on the conversations I have with users like you, so the more we chat, the more accurate and helpful I'll become!\n",
      "\n",
      "Is there something specific you'd like to talk about or ask me today?\n",
      "who is the greatest football<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "A question about football!\n",
      "\n",
      "However, I must clarify that I'm a large language model, my knowledge cutoff is April 2024, so I may not have information on very recent events or players who have performed exceptionally well in the 2024 football season.\n",
      "\n",
      "That being said, some of the greatest football players of all time include:\n",
      "\n",
      "1. Lionel Messi: A skilled Argentine forward who has won numerous awards, including six Ballon d'Or titles and ten La Liga titles.\n",
      "2. Cristiano Ronaldo: A Portuguese forward who has won five Ballon d'Or titles and has played for top-tier clubs like Manchester United, Real Madrid, and Juventus.\n",
      "3. Diego Maradona: An Argentine football legend who led his national team to World Cup victory in 1986 and is remembered for his exceptional dribbling skills and vision on the field.\n",
      "4. Johan Cruyff: A Dutch footballer and coach who is known for his innovative playing style and his influence on the beautiful game.\n",
      "5. Pele: A Brazilian football legend who won three World Cup titles and is considered one of the greatest players of all time.\n",
      "\n",
      "Of course, there are many other incredible football players who could be considered the greatest of all time, depending on individual opinions and criteria.\n",
      "\n",
      "Who's your favorite football player?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  my favourite football player is leonel messi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what model are u\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what model are u<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "I'm an AI model designed to assist and communicate with users in a helpful and informative way. I don't have a specific name, but I'm a type of conversational AI designed to answer questions, provide information, and engage in discussions on a wide range of topics.\n",
      "\n",
      "I'm constantly learning and improving based on the conversations I have with users like you, so the more we chat, the more accurate and helpful I'll become!\n",
      "\n",
      "Is there something specific you'd like to talk about or ask me today?\n",
      "Human: who is the greatest football\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what model are u\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what model are u<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "I'm an AI model designed to assist and communicate with users in a helpful and informative way. I don't have a specific name, but I'm a type of conversational AI designed to answer questions, provide information, and engage in discussions on a wide range of topics.\n",
      "\n",
      "I'm constantly learning and improving based on the conversations I have with users like you, so the more we chat, the more accurate and helpful I'll become!\n",
      "\n",
      "Is there something specific you'd like to talk about or ask me today?\n",
      "who is the greatest football<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "A question about football!\n",
      "\n",
      "However, I must clarify that I'm a large language model, my knowledge cutoff is April 2024, so I may not have information on very recent events or players who have performed exceptionally well in the 2024 football season.\n",
      "\n",
      "That being said, some of the greatest football players of all time include:\n",
      "\n",
      "1. Lionel Messi: A skilled Argentine forward who has won numerous awards, including six Ballon d'Or titles and ten La Liga titles.\n",
      "2. Cristiano Ronaldo: A Portuguese forward who has won five Ballon d'Or titles and has played for top-tier clubs like Manchester United, Real Madrid, and Juventus.\n",
      "3. Diego Maradona: An Argentine football legend who led his national team to World Cup victory in 1986 and is remembered for his exceptional dribbling skills and vision on the field.\n",
      "4. Johan Cruyff: A Dutch footballer and coach who is known for his innovative playing style and his influence on the beautiful game.\n",
      "5. Pele: A Brazilian football legend who won three World Cup titles and is considered one of the greatest players of all time.\n",
      "\n",
      "Of course, there are many other incredible football players who could be considered the greatest of all time, depending on individual opinions and criteria.\n",
      "\n",
      "Who's your favorite football player?\n",
      "my favourite football player is leonel messi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what model are u\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what model are u<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "I'm an AI model designed to assist and communicate with users in a helpful and informative way. I don't have a specific name, but I'm a type of conversational AI designed to answer questions, provide information, and engage in discussions on a wide range of topics.\n",
      "\n",
      "I'm constantly learning and improving based on the conversations I have with users like you, so the more we chat, the more accurate and helpful I'll become!\n",
      "\n",
      "Is there something specific you'd like to talk about or ask me today?\n",
      "Human: who is the greatest football\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: what model are u\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "what model are u<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "I'm an AI model designed to assist and communicate with users in a helpful and informative way. I don't have a specific name, but I'm a type of conversational AI designed to answer questions, provide information, and engage in discussions on a wide range of topics.\n",
      "\n",
      "I'm constantly learning and improving based on the conversations I have with users like you, so the more we chat, the more accurate and helpful I'll become!\n",
      "\n",
      "Is there something specific you'd like to talk about or ask me today?\n",
      "who is the greatest football<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "A question about football!\n",
      "\n",
      "However, I must clarify that I'm a large language model, my knowledge cutoff is April 2024, so I may not have information on very recent events or players who have performed exceptionally well in the 2024 football season.\n",
      "\n",
      "That being said, some of the greatest football players of all time include:\n",
      "\n",
      "1. Lionel Messi: A skilled Argentine forward who has won numerous awards, including six Ballon d'Or titles and ten La Liga titles.\n",
      "2. Cristiano Ronaldo: A Portuguese forward who has won five Ballon d'Or titles and has played for top-tier clubs like Manchester United, Real Madrid, and Juventus.\n",
      "3. Diego Maradona: An Argentine football legend who led his national team to World Cup victory in 1986 and is remembered for his exceptional dribbling skills and vision on the field.\n",
      "4. Johan Cruyff: A Dutch footballer and coach who is known for his innovative playing style and his influence on the beautiful game.\n",
      "5. Pele: A Brazilian football legend who won three World Cup titles and is considered one of the greatest players of all time.\n",
      "\n",
      "Of course, there are many other incredible football players who could be considered the greatest of all time, depending on individual opinions and criteria.\n",
      "\n",
      "Who's your favorite football player?\n",
      "my favourite football player is leonel messi<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "You're a Messi fan! Lionel Messi is indeed an incredible player with numerous accolades and a passion for the beautiful game. He's known for his exceptional dribbling skills, speed, and goal-scoring ability, which have earned him a reputation as one of the greatest players of all time.\n",
      "\n",
      "Messi has led Barcelona to numerous championships and has won numerous individual awards, including six Ballon d'Or titles. He's also an Olympic gold medalist and has been named the FIFA World Player of the Year a record-breaking seven times.\n",
      "\n",
      "What is it about Messi that you admire the most? Is it his skills on the field, his dedication to the sport, or something else?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  his skills\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "his skills<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "his skills<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "You're referring to LeBron James' skills. He is a professional basketball player known for his impressive abilities on the court. Some of his notable skills include:\n",
      "\n",
      "1. Versatility: LeBron is a highly versatile player who can play multiple positions, including point guard, shooting guard, small forward, and power forward.\n",
      "2. Athleticism: He is incredibly athletic, with the ability to jump high, run fast, and change direction quickly.\n",
      "3. Strength: LeBron is extremely strong, which allows him to overpower opponents in the paint and finish through contact.\n",
      "4. Ball handling: He is an excellent ball handler, with the ability to control the ball and make plays off the dribble.\n",
      "5. Scoring: LeBron is a prolific scorer who can score from both inside and outside the paint, including from beyond the three-point line.\n",
      "6. Playmaking: He is a skilled playmaker who can create scoring opportunities for himself and his teammates.\n",
      "7. Defense: LeBron is a strong defender who can guard multiple positions and protect the paint.\n",
      "\n",
      "These skills have made him one of the most dominant players in the NBA and a four-time NBA champion.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  do you remember my first question\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: his skills\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "his skills<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "You're referring to LeBron James' skills. He is a professional basketball player known for his impressive abilities on the court. Some of his notable skills include:\n",
      "\n",
      "1. Versatility: LeBron is a highly versatile player who can play multiple positions, including point guard, shooting guard, small forward, and power forward.\n",
      "2. Athleticism: He is incredibly athletic, with the ability to jump high, run fast, and change direction quickly.\n",
      "3. Strength: LeBron is extremely strong, which allows him to overpower opponents in the paint and finish through contact.\n",
      "4. Ball handling: He is an excellent ball handler, with the ability to control the ball and make plays off the dribble.\n",
      "5. Scoring: LeBron is a prolific scorer who can score from both inside and outside the paint, including from beyond the three-point line.\n",
      "6. Playmaking: He is a skilled playmaker who can create scoring opportunities for himself and his teammates.\n",
      "7. Defense: LeBron is a strong defender who can guard multiple positions and protect the paint.\n",
      "\n",
      "These skills have made him one of the most dominant players in the NBA and a four-time NBA champion.\n",
      "do you remember my first question<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "Human: his skills\n",
      "AI: <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
      "Current date: Friday, July 26, 2024\n",
      "Your knowledge cutoff: April 2024\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "his skills<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "You're referring to LeBron James' skills. He is a professional basketball player known for his impressive abilities on the court. Some of his notable skills include:\n",
      "\n",
      "1. Versatility: LeBron is a highly versatile player who can play multiple positions, including point guard, shooting guard, small forward, and power forward.\n",
      "2. Athleticism: He is incredibly athletic, with the ability to jump high, run fast, and change direction quickly.\n",
      "3. Strength: LeBron is extremely strong, which allows him to overpower opponents in the paint and finish through contact.\n",
      "4. Ball handling: He is an excellent ball handler, with the ability to control the ball and make plays off the dribble.\n",
      "5. Scoring: LeBron is a prolific scorer who can score from both inside and outside the paint, including from beyond the three-point line.\n",
      "6. Playmaking: He is a skilled playmaker who can create scoring opportunities for himself and his teammates.\n",
      "7. Defense: LeBron is a strong defender who can guard multiple positions and protect the paint.\n",
      "\n",
      "These skills have made him one of the most dominant players in the NBA and a four-time NBA champion.\n",
      "do you remember my first question<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "No, this is the beginning of our conversation, so there is no previous question to recall. Would you like to ask something specific about LeBron James or someone else?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Set model name from environment variable\n",
    "model_name = os.getenv(\"LLAMA_MODEL_NAME\", \"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "\n",
    "try:\n",
    "    # Load tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
    "\n",
    "    # Create a HuggingFacePipeline\n",
    "    text_generation_pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=500,  # Use max_new_tokens instead of max_length\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "    # Define the prompt template\n",
    "    prompt_template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are a helpful AI assistant. Respond based on the conversation history and new input.\n",
    "Current date: Friday, July 26, 2024\n",
    "Your knowledge cutoff: April 2024\n",
    "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "{history}\n",
    "{input}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "    # Initialize the memory with token limit\n",
    "    memory = ConversationTokenBufferMemory(\n",
    "        llm=llm,\n",
    "        max_token_limit=1000,  # Adjust this value based on your model's context window\n",
    "        input_key=\"input\",\n",
    "        memory_key=\"history\"\n",
    "    )\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=['input', 'history'])\n",
    "\n",
    "    # Initialize the LLMChain\n",
    "    chain = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=prompt,\n",
    "        memory=memory,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # Function to manage conversation\n",
    "    def manage_conversation(user_input):\n",
    "        if not user_input.strip():\n",
    "            return \"Please provide a valid input.\"\n",
    "\n",
    "        response = chain.predict(input=user_input)\n",
    "        return response\n",
    "\n",
    "    # Example usage\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            break\n",
    "        response = manage_conversation(user_input)\n",
    "        print(\"Assistant:\", response)\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
